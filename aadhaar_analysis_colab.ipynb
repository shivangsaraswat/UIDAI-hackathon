{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Aadhaar Demographic Data Analysis\n",
                "## UIDAI Hackathon Submission\n",
                "---\n",
                "\n",
                "This notebook presents a comprehensive analysis of anonymized Aadhaar demographic update data. The pipeline processes approximately 2 million records to extract meaningful insights about demographic trends across different age groups, states, and time periods.\n",
                "\n",
                "### Key Highlights\n",
                "- **Automated Data Pipeline**: Programmatic extraction and processing of large-scale CSV datasets\n",
                "- **Data Engineering**: Merging multiple data partitions into a unified DataFrame\n",
                "- **Visual Analytics**: High-resolution visualizations showcasing demographic patterns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 1: Import Required Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Installing dependencies\n",
                "!pip install -q seaborn matplotlib pandas numpy\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import zipfile\n",
                "import os\n",
                "\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "sns.set_palette('husl')\n",
                "\n",
                "print('‚úÖ Libraries imported successfully!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 2: Upload Dataset\n",
                "\n",
                "The dataset (`aadhaar-hackathon.zip`) contains anonymized Aadhaar demographic update records. Running the cell below will prompt for file upload."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "\n",
                "uploaded = files.upload()\n",
                "zip_filename = list(uploaded.keys())[0]\n",
                "print(f\"\\n‚úÖ Dataset uploaded: {zip_filename}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 3: Extract Dataset\n",
                "\n",
                "Extracting the compressed archive to access the CSV data files."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "extract_path = '/content/data'\n",
                "os.makedirs(extract_path, exist_ok=True)\n",
                "\n",
                "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
                "    zip_ref.extractall(extract_path)\n",
                "\n",
                "print(f'‚úÖ Dataset extracted to: {extract_path}')\n",
                "\n",
                "# Display extracted files\n",
                "print('\\nüìÇ Extracted files:')\n",
                "for root, dirs, files_list in os.walk(extract_path):\n",
                "    for file in files_list:\n",
                "        print(f'  - {os.path.join(root, file)}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 4: Load and Merge CSV Files\n",
                "\n",
                "The dataset is partitioned across multiple CSV files. This step consolidates all partitions into a single DataFrame for unified analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "csv_files = []\n",
                "for root, dirs, filenames in os.walk(extract_path):\n",
                "    for f in filenames:\n",
                "        if f.endswith('.csv'):\n",
                "            csv_files.append(os.path.join(root, f))\n",
                "\n",
                "print(f'Found {len(csv_files)} CSV files')\n",
                "\n",
                "df = pd.concat([pd.read_csv(f) for f in csv_files], ignore_index=True)\n",
                "\n",
                "print(f'\\n‚úÖ Loaded {len(df):,} rows of data')\n",
                "print(f'\\nColumns: {list(df.columns)}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 5: Data Exploration\n",
                "\n",
                "Examining the structure and statistical properties of the dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preview of the dataset\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dataset structure and memory usage\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Statistical summary\n",
                "df.describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 6: Age Group Distribution Analysis\n",
                "\n",
                "Visualizing the distribution of demographic updates across different age groups."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Identify age-related columns\n",
                "age_cols = [col for col in df.columns if 'age' in col.lower() or 'demo' in col.lower()]\n",
                "print(f'Age-related columns found: {age_cols}')\n",
                "\n",
                "# Calculate totals for each age group\n",
                "age_totals = df[age_cols].sum()\n",
                "\n",
                "# Pie chart visualization\n",
                "plt.figure(figsize=(10, 10))\n",
                "colors = sns.color_palette('husl', len(age_totals))\n",
                "plt.pie(age_totals, labels=age_totals.index, autopct='%1.1f%%', startangle=90, colors=colors)\n",
                "plt.title('Age Group Distribution of Demographic Updates', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig('age_distribution_pie.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print('\\n‚úÖ Age distribution pie chart generated')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Bar chart for age group comparison\n",
                "plt.figure(figsize=(12, 6))\n",
                "age_totals.plot(kind='bar', color=colors, edgecolor='black', linewidth=0.5)\n",
                "plt.title('Total Update Count by Age Group', fontsize=14, fontweight='bold')\n",
                "plt.xlabel('Age Group')\n",
                "plt.ylabel('Total Updates')\n",
                "plt.xticks(rotation=45, ha='right')\n",
                "plt.tight_layout()\n",
                "plt.savefig('age_group_updates.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print('\\n‚úÖ Age group bar chart generated')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 7: Time Series Analysis\n",
                "\n",
                "Analyzing the temporal trends in demographic updates to identify patterns over time."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Identify date column\n",
                "date_cols = [col for col in df.columns if 'date' in col.lower()]\n",
                "date_col = date_cols[0] if date_cols else None\n",
                "\n",
                "if date_col:\n",
                "    # Convert to datetime\n",
                "    df[date_col] = pd.to_datetime(df[date_col], format='%d-%m-%Y', errors='coerce')\n",
                "    \n",
                "    # Aggregate daily updates\n",
                "    daily_updates = df.groupby(date_col)[age_cols].sum()\n",
                "    \n",
                "    # Time series plot\n",
                "    plt.figure(figsize=(14, 6))\n",
                "    for col in age_cols:\n",
                "        plt.plot(daily_updates.index, daily_updates[col], label=col, linewidth=2)\n",
                "    \n",
                "    plt.title('Daily Demographic Updates Over Time', fontsize=14, fontweight='bold')\n",
                "    plt.xlabel('Date')\n",
                "    plt.ylabel('Number of Updates')\n",
                "    plt.legend(title='Age Group', loc='upper right')\n",
                "    plt.grid(True, alpha=0.3)\n",
                "    plt.tight_layout()\n",
                "    plt.savefig('time_series.png', dpi=150, bbox_inches='tight')\n",
                "    plt.show()\n",
                "    \n",
                "    print('\\n‚úÖ Time series analysis completed')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 8: State-wise Geographic Analysis\n",
                "\n",
                "Examining the distribution of demographic updates across different states."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Identify state column\n",
                "state_cols = [col for col in df.columns if 'state' in col.lower()]\n",
                "state_col = state_cols[0] if state_cols else None\n",
                "\n",
                "if state_col:\n",
                "    # State-wise aggregation\n",
                "    state_summary = df.groupby(state_col)[age_cols].sum()\n",
                "    state_totals = state_summary.sum(axis=1).sort_values(ascending=True)\n",
                "    \n",
                "    # Top 15 states visualization\n",
                "    top_states = state_totals.tail(15)\n",
                "    \n",
                "    plt.figure(figsize=(12, 8))\n",
                "    bars = plt.barh(top_states.index, top_states.values, color=sns.color_palette('viridis', len(top_states)))\n",
                "    plt.title('Top 15 States by Total Demographic Updates', fontsize=14, fontweight='bold')\n",
                "    plt.xlabel('Total Updates')\n",
                "    plt.ylabel('State')\n",
                "    \n",
                "    # Add value labels\n",
                "    for bar, val in zip(bars, top_states.values):\n",
                "        plt.text(val + 1000, bar.get_y() + bar.get_height()/2, f'{val:,.0f}', va='center', fontsize=9)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig('state_wise_updates.png', dpi=150, bbox_inches='tight')\n",
                "    plt.show()\n",
                "    \n",
                "    print('\\n‚úÖ State-wise analysis completed')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 9: District-level Insights\n",
                "\n",
                "Drilling down to district-level data for granular geographic analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Identify district column\n",
                "district_cols = [col for col in df.columns if 'district' in col.lower()]\n",
                "district_col = district_cols[0] if district_cols else None\n",
                "\n",
                "if district_col:\n",
                "    # District-wise aggregation\n",
                "    district_summary = df.groupby(district_col)[age_cols].sum()\n",
                "    district_totals = district_summary.sum(axis=1).sort_values(ascending=False)\n",
                "    \n",
                "    # Top 20 districts\n",
                "    top_districts = district_totals.head(20)\n",
                "    \n",
                "    print('Top 20 Districts by Total Updates:')\n",
                "    print('-' * 40)\n",
                "    for i, (district, count) in enumerate(top_districts.items(), 1):\n",
                "        print(f'{i:2}. {district}: {count:,.0f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 10: Summary Statistics\n",
                "\n",
                "Consolidated summary of key findings from the analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('=' * 60)\n",
                "print('ANALYSIS SUMMARY')\n",
                "print('=' * 60)\n",
                "print(f'\\nüìä Total Records Processed: {len(df):,}')\n",
                "print(f'üìÖ Date Range: {df[date_col].min().strftime(\"%d-%m-%Y\")} to {df[date_col].max().strftime(\"%d-%m-%Y\")}')\n",
                "print(f'üó∫Ô∏è  States Covered: {df[state_col].nunique()}')\n",
                "print(f'üìç Districts Covered: {df[district_col].nunique()}')\n",
                "print(f'\\nüìà Total Demographic Updates:')\n",
                "for col in age_cols:\n",
                "    print(f'   - {col}: {df[col].sum():,}')\n",
                "print(f'\\n   Total: {df[age_cols].sum().sum():,}')\n",
                "print('\\n' + '=' * 60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 11: Download Generated Visualizations\n",
                "\n",
                "Downloading all generated charts and outputs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import shutil\n",
                "\n",
                "# Create output directory\n",
                "output_dir = '/content/outputs'\n",
                "os.makedirs(output_dir, exist_ok=True)\n",
                "\n",
                "# Move generated images to output folder\n",
                "for img in ['age_distribution_pie.png', 'age_group_updates.png', 'time_series.png', 'state_wise_updates.png']:\n",
                "    if os.path.exists(img):\n",
                "        shutil.copy(img, output_dir)\n",
                "\n",
                "# Create zip archive\n",
                "shutil.make_archive('/content/analysis_outputs', 'zip', output_dir)\n",
                "\n",
                "# Download\n",
                "from google.colab import files\n",
                "files.download('/content/analysis_outputs.zip')\n",
                "\n",
                "print('\\n‚úÖ All visualizations downloaded successfully!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Conclusion\n",
                "\n",
                "This analysis pipeline successfully processes large-scale Aadhaar demographic data to reveal meaningful patterns in demographic updates. The visualizations demonstrate clear trends across age groups, geographic regions, and time periods, providing actionable insights for understanding demographic update behavior."
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": [],
            "toc_visible": true
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}